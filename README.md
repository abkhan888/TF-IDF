TF-IDF (Term Frequency-Inverse Document Frequency)
TF-IDF is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (corpus). It is widely used in text mining and information retrieval to identify words that carry significant meaning. TF-IDF combines two metrics:

Term Frequency (TF):

Definition: Measures how frequently a term appears in a document.
Formula:
TF
(
ğ‘¡
,
ğ‘‘
)
=
NumberÂ ofÂ timesÂ termÂ 
ğ‘¡
Â appearsÂ inÂ documentÂ 
ğ‘‘
TotalÂ numberÂ ofÂ termsÂ inÂ documentÂ 
ğ‘‘
TF(t,d)= 
TotalÂ numberÂ ofÂ termsÂ inÂ documentÂ d
NumberÂ ofÂ timesÂ termÂ tÂ appearsÂ inÂ documentÂ d
â€‹
 
Purpose: Highlights the importance of a term within a specific document.
Inverse Document Frequency (IDF):

Definition: Measures how important a term is across the entire corpus.
Formula:
IDF
(
ğ‘¡
,
ğ·
)
=
log
â¡
(
TotalÂ numberÂ ofÂ documents
NumberÂ ofÂ documentsÂ containingÂ termÂ 
ğ‘¡
)
IDF(t,D)=log( 
NumberÂ ofÂ documentsÂ containingÂ termÂ t
TotalÂ numberÂ ofÂ documents
â€‹
 )
 
Purpose: Downscales terms that appear in many documents, reducing their influence on the analysis.
TF-IDF Score:

Formula:
TF-IDF
(
ğ‘¡
,
ğ‘‘
,
ğ·
)
=
TF
(
ğ‘¡
,
ğ‘‘
)
Ã—
IDF
(
ğ‘¡
,
ğ·
)

TF-IDF(t,d,D)=TF(t,d)Ã—IDF(t,D)

Purpose: Provides a composite score that highlights important terms that are frequent in a document but not common across the corpus.
